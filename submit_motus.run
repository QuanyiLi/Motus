#!/bin/bash
#SBATCH --job-name=motus_train
#SBATCH --output=/home/lfeng/task_logs/motus_%j.log
#SBATCH --partition=h100
#SBATCH --qos=vita
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=64
#SBATCH --gpus-per-node=4
#SBATCH --nodes=3
#SBATCH --time=24:00:00
#SBATCH --mem=200G

export MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=29500

# Directory paths on remote server
MOTUS_DIR="/work/vita/lanfeng/vlas/Motus"
DATA_ROOT="/work/vita/lanfeng/vlas/vla/wise_dataset/merged_dataset"
CONFIG_FILE="configs/wise_dataset.yaml"

# Important: set CUDA_HOME and add Conda's nvcc to PATH if installed via conda
# export CUDA_HOME=${CONDA_PREFIX:-/usr/local/cuda}
# export PATH=$CUDA_HOME/bin:$PATH

# NOTE: Change directory to Motus to ensure relative paths work (e.g. configs/zero1.json)
cd ${MOTUS_DIR}

srun torchrun \
    --nnodes=3 \
    --nproc_per_node=4 \
    --rdzv_id=$SLURM_JOB_ID \
    --rdzv_backend=c10d \
    --rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT \
    train/train.py \
    --deepspeed configs/zero1.json \
    --config ${CONFIG_FILE} \
    --run_name "motus_wise_dataset" \
    --report_to wandb
