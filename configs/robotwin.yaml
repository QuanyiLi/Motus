common:
  # Robot dimensions
  action_dim: 14         # Robot action dimension
  state_dim: 14          # Robot state dimension
  
  # Video settings  
  num_video_frames: 8    # Number of video frames to predict
  video_height: 384      # Video frame height
  video_width: 320       # Video frame width
  
  # Sampling strategy parameters
  global_downsample_rate: 3     # Global downsampling (e.g., 30Hz -> 20Hz)
  video_action_freq_ratio: 2    # Video:Action frequency ratio
  
  # Training settings

# Dataset configuration
dataset:
  # Dataset type
  type: "robotwin"  # Dataset type: "robotwin"
  
  # Dataset paths
  dataset_dir: "/share/dataset/preprocess/robotwin2"
  
  # RobotWin specific parameters
  data_mode: "both"  # "clean", "randomized", or "both"
  task_mode: "multi"  # "single" or "multi"
  task_name: null     # Required for single task mode (e.g., "adjust_bottle")
  # Optional cap: limit randomized split to first N episodes per task
  # randomized_limit_per_task: 50
  
  # Data loading settings
  max_episodes: null  # Maximum episodes for debugging (null = all)
  
  # Data augmentation
  image_aug: false    # Whether to apply image augmentation

# Model configuration
model:
  # WAN Video Model settings
  wan:
    config_path: "/share/home/bhz/pretrained_models/Wan2.2-TI2V-5B"
    checkpoint_path: "/share/home/bhz/pretrained_models/Wan2.2-TI2V-5B"
    vae_path: "/share/home/bhz/pretrained_models/Wan2.2-TI2V-5B/Wan2.2_VAE.pth"
    precision: "bfloat16"
  
  # VLM settings
  vlm:
    checkpoint_path: "/share/home/bhz/pretrained_models/Qwen3-VL-2B-Instruct"
    precision: "bfloat16"
    frozen: true              # Whether to freeze VLM parameters
  
  # Action Expert configuration
  action_expert:
    # Architecture parameters (configurable)
    hidden_size: 1024       # Hidden dimension (must be multiple of 128 for head_dim=128)
    ffn_dim_multiplier: 4   # FFN = hidden_size * multiplier
    
    # Normalization and regularization
    norm_eps: 1e-5         # Layer norm epsilon
  
  # Understanding Expert configuration
  und_expert:
    # Architecture parameters (configurable)
    hidden_size: 512        # Hidden dimension for understanding expert
    ffn_dim_multiplier: 4   # FFN = hidden_size * multiplier
    
    # Normalization and regularization
    norm_eps: 1e-5         # Layer norm epsilon
    
    # VLM adapter settings
    vlm:
      input_dim: 2048       # VLM feature dimension (input)
      projector_type: "mlp3x_silu"  # Adapter type
    
  # Time distribution settings
  time_distribution:
    timestep_sample_method: "logit_normal"    # "logit_normal" or "uniform"
    sigmoid_scale: 1.0                        # Controls distribution shape (higher = more concentrated around 0.5)
    min_t: 0.0                               # Minimum time value for training
    max_t: 1.0                               # Maximum time value for training
    
  # Inference settings
  inference:
    num_inference_timesteps: 10               # Number of denoising steps during inference
    
  # Loss weights
  loss_weights:
    video_loss_weight: 1.0       # Weight for video reconstruction loss
    action_loss_weight: 1.0     # Weight for action prediction loss
    
  # EMA settings (not used currently)
  ema:
    enabled: false
    update_after_step: 0
    inv_gamma: 1.0
    power: 0.75
    min_value: 0.0
    max_value: 0.9999

# Training configuration
training:
  # Optimization settings
  batch_size: 8
  max_steps: 1000000
  learning_rate: 5.0e-5
  # Optional: separate learning rate for WAN (video model). If omitted, falls back to learning_rate
  # wan_learning_rate: 5.0e-5
  weight_decay: 0.01
  
  # Scheduler settings
  scheduler_type: "linear"
  warmup_steps: 200
  cycle_length: 5000000   # To5al cycle length for scheduler
  f_max: 0.99           # Maximum learning rate multiplier after warmup
  f_min: 0.4            # Minimum learning rate multiplier at end
  
  # Gradient settings
  grad_clip_norm: 0.5
  
  # Mixed precision
  use_amp: true          # Use automatic mixed precision
  
  # Distributed training
  find_unused_parameters: false

# System settings
system:
  # Paths
  checkpoint_dir: "./checkpoints"
  log_level: "INFO"
  
  # Intervals
  log_interval: 1       # Log every N steps
  save_interval: 5000    # Save every N steps  
  val_interval: 500     # Validate every N steps
  
  # Hardware settings
  num_workers: 16         # Number of dataloader workers
  pin_memory: true       # Pin memory for faster GPU transfer

# Logging settings  
logging:
  # Reporting - support multiple logging backends
  report_to: "wandb"  # Options: "wandb", "tensorboard", "all", "none"
  
  # Weights & Biases settings
  wandb_project: "motus"
  
  # TensorBoard settings
  tensorboard_log_dir: "tensorboard_logs"
  
  # Run naming
  run_name: null  # Optional run name (timestamp will be appended)
  

# Resume training settings
resume:
  checkpoint_path: null  # Path to checkpoint to resume from
  
# Finetune settings 
finetune:
  checkpoint_path: null  # (directory containing mp_rank_00_model_states.pt)
